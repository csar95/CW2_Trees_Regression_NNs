{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "def preprocessing(data, labels, val=True):\n",
    "    \n",
    "    data = pd.read_csv(data)\n",
    "    labels = pd.read_csv(labels)\n",
    "\n",
    "    if(val):\n",
    "        ## ---------------- Data preparation ---------------- ##\n",
    "        X_train = []\n",
    "        for i in range(data.shape[0]):\n",
    "            img = np.uint8(data.iloc[i])\n",
    "            edited = cv2.Canny(img, 10, 30)\n",
    "            edited = cv2.GaussianBlur(edited, (5, 5), 0)\n",
    "            X_train.append(edited.reshape((1,-1))[0])\n",
    "\n",
    "        data = pd.DataFrame(X_train)\n",
    "        ## -------------------------------------------------- ##\n",
    "\n",
    "    return data, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = preprocessing(data='data/x_train_gr_smpl.csv', labels='data/y_train_smpl.csv')\n",
    "X_train['label'] = y_train\n",
    "X_train = X_train.sample(frac=1)\n",
    "\n",
    "X_test, y_test = preprocessing(data='data/x_test_gr_smpl.csv', labels='data/y_test_smpl.csv')\n",
    "X_test['label'] = y_test\n",
    "X_test = X_test.sample(frac=1)\n",
    "\n",
    "y_train = X_train['label']\n",
    "X_train = X_train.iloc[:, :-1]\n",
    "\n",
    "y_test = X_test['label']\n",
    "X_test = X_test.iloc[:, :-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.utils import to_categorical\n",
    "\n",
    "y_train = to_categorical(y_train)\n",
    "y_test = to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[32]\n",
      "[0.1254902]\n",
      "(48, 48, 1)\n"
     ]
    }
   ],
   "source": [
    "IMG_SIZE = 48\n",
    "\n",
    "X_train = np.array(X_train).reshape(-1, IMG_SIZE, IMG_SIZE, 1)\n",
    "X_test = np.array(X_test).reshape(-1, IMG_SIZE, IMG_SIZE, 1)\n",
    "\n",
    "print(X_train[0][0][0])\n",
    "\n",
    "X_train = X_train/255.0\n",
    "X_test = X_test/255.0\n",
    "\n",
    "print(X_train[0][0][0])\n",
    "print(X_train.shape[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\layers\\core.py:143: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "Train on 12660 samples, validate on 4170 samples\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/20\n",
      "12660/12660 [==============================] - 17s 1ms/sample - loss: 0.5862 - acc: 0.7897 - val_loss: 0.3197 - val_acc: 0.8957\n",
      "Epoch 2/20\n",
      "12660/12660 [==============================] - 14s 1ms/sample - loss: 0.1802 - acc: 0.9311 - val_loss: 0.2162 - val_acc: 0.9170\n",
      "Epoch 3/20\n",
      "12660/12660 [==============================] - 14s 1ms/sample - loss: 0.1131 - acc: 0.9576 - val_loss: 0.2442 - val_acc: 0.9163\n",
      "Epoch 4/20\n",
      "12660/12660 [==============================] - 14s 1ms/sample - loss: 0.0803 - acc: 0.9698 - val_loss: 0.1952 - val_acc: 0.9314\n",
      "Epoch 5/20\n",
      "12660/12660 [==============================] - 14s 1ms/sample - loss: 0.0592 - acc: 0.9783 - val_loss: 0.2459 - val_acc: 0.9324\n",
      "Epoch 6/20\n",
      "12660/12660 [==============================] - 14s 1ms/sample - loss: 0.0470 - acc: 0.9835 - val_loss: 0.2655 - val_acc: 0.9393\n",
      "Epoch 7/20\n",
      "12660/12660 [==============================] - 15s 1ms/sample - loss: 0.0354 - acc: 0.9871 - val_loss: 0.2364 - val_acc: 0.9446\n",
      "Epoch 8/20\n",
      "12660/12660 [==============================] - 14s 1ms/sample - loss: 0.0274 - acc: 0.9901 - val_loss: 0.2745 - val_acc: 0.9434\n",
      "Epoch 9/20\n",
      "12660/12660 [==============================] - 14s 1ms/sample - loss: 0.0254 - acc: 0.9906 - val_loss: 0.2921 - val_acc: 0.9393\n",
      "Epoch 10/20\n",
      "12660/12660 [==============================] - 14s 1ms/sample - loss: 0.0195 - acc: 0.9934 - val_loss: 0.2885 - val_acc: 0.9429\n",
      "Epoch 11/20\n",
      "12660/12660 [==============================] - 14s 1ms/sample - loss: 0.0227 - acc: 0.9915 - val_loss: 0.3842 - val_acc: 0.9261\n",
      "Epoch 12/20\n",
      "12660/12660 [==============================] - 14s 1ms/sample - loss: 0.0204 - acc: 0.9931 - val_loss: 0.3120 - val_acc: 0.9379\n",
      "Epoch 13/20\n",
      "12660/12660 [==============================] - 14s 1ms/sample - loss: 0.0154 - acc: 0.9942 - val_loss: 0.2874 - val_acc: 0.9441\n",
      "Epoch 14/20\n",
      "12660/12660 [==============================] - 14s 1ms/sample - loss: 0.0126 - acc: 0.9961 - val_loss: 0.3047 - val_acc: 0.9427\n",
      "Epoch 15/20\n",
      "12660/12660 [==============================] - 14s 1ms/sample - loss: 0.0140 - acc: 0.9957 - val_loss: 0.3589 - val_acc: 0.9436\n",
      "Epoch 16/20\n",
      "12660/12660 [==============================] - 14s 1ms/sample - loss: 0.0123 - acc: 0.9960 - val_loss: 0.3385 - val_acc: 0.9434\n",
      "Epoch 17/20\n",
      "12660/12660 [==============================] - 14s 1ms/sample - loss: 0.0084 - acc: 0.9970 - val_loss: 0.3297 - val_acc: 0.9532\n",
      "Epoch 18/20\n",
      "12660/12660 [==============================] - 14s 1ms/sample - loss: 0.0119 - acc: 0.9961 - val_loss: 0.3486 - val_acc: 0.9494\n",
      "Epoch 19/20\n",
      "12660/12660 [==============================] - 14s 1ms/sample - loss: 0.0101 - acc: 0.9962 - val_loss: 0.3291 - val_acc: 0.9422\n",
      "Epoch 20/20\n",
      "12660/12660 [==============================] - 14s 1ms/sample - loss: 0.0088 - acc: 0.9971 - val_loss: 0.3900 - val_acc: 0.9477\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten, Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "\n",
    "dense_layers = [1]\n",
    "layer_sizes = [64]\n",
    "conv_layers = [3]\n",
    "\n",
    "for dense_layer in dense_layers:\n",
    "    for layer_size in layer_sizes:\n",
    "        for conv_layer in conv_layers:\n",
    "\n",
    "#             NAME = f\"{conv_layer}-conv-{layer_size}-nodes-{dense_layer}-dense-{int(time.time())}\"\n",
    "#             tensorboard = TensorBoard(log_dir=f\"logs\\{NAME}\")\n",
    "\n",
    "            model = Sequential()\n",
    "\n",
    "            model.add(Conv2D(layer_size, (3, 3), input_shape=X_train.shape[1:], activation='relu'))\n",
    "            model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "            for l in range(conv_layer-1):\n",
    "                model.add(Conv2D(layer_size, (3, 3), activation='relu'))\n",
    "                model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "            model.add(Flatten())\n",
    "            for l in range(dense_layer):\n",
    "                model.add(Dense(layer_size, activation='relu'))\n",
    "                model.add(Dropout(0.2))\n",
    "\n",
    "            model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "            model.compile(loss=\"categorical_crossentropy\",\n",
    "                         optimizer=\"adam\",\n",
    "                         metrics=[\"accuracy\"])\n",
    "\n",
    "            model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=20) # , callbacks=[tensorboard])\n",
    "            \n",
    "# model.save('6ax3-CNN.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = tf.keras.models.load_model(\"6ax3-CNN.model\")\n",
    "\n",
    "test = \n",
    "prediction = model.predict('')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
