{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def preprocessing(val=True):\n",
    "    \n",
    "    data = pd.read_csv('data/x_train_gr_smpl.csv')\n",
    "    labels = pd.read_csv('data/y_train_smpl.csv')\n",
    "\n",
    "    if(val):\n",
    "        ## ---------------- Data preparation ---------------- ##\n",
    "        X_train = []\n",
    "        for i in range(data.shape[0]):\n",
    "            img = np.uint8(data.iloc[i])\n",
    "            edited = cv2.Canny(img, 10, 30)\n",
    "            edited = cv2.GaussianBlur(edited, (5, 5), 0)\n",
    "            X_train.append(edited.reshape((1,-1))[0])\n",
    "\n",
    "        data = pd.DataFrame(X_train)\n",
    "        ## -------------------------------------------------- ##\n",
    "\n",
    "    return data, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data, labels = preprocessing()\n",
    "data['label'] = labels\n",
    "\n",
    "X = data.iloc[:, :-1]\n",
    "y = data['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.utils import to_categorical\n",
    "y = to_categorical(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\n",
      "[0.]\n",
      "(48, 48, 1)\n"
     ]
    }
   ],
   "source": [
    "IMG_SIZE = 48\n",
    "\n",
    "X_train = np.array(X_train).reshape(-1, IMG_SIZE, IMG_SIZE, 1)\n",
    "X_test = np.array(X_test).reshape(-1, IMG_SIZE, IMG_SIZE, 1)\n",
    "\n",
    "print(X_train[0][0][0])\n",
    "\n",
    "X_train = X_train/255.0\n",
    "X_test = X_test/255.0\n",
    "\n",
    "print(X_train[0][0][0])\n",
    "print(X_train.shape[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 8482 samples, validate on 4178 samples\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/20\n",
      "8482/8482 [==============================] - 5s 587us/sample - loss: 0.7284 - acc: 0.7386 - val_loss: 0.2414 - val_acc: 0.8935\n",
      "Epoch 2/20\n",
      "8482/8482 [==============================] - 3s 367us/sample - loss: 0.2141 - acc: 0.9151 - val_loss: 0.1291 - val_acc: 0.9493\n",
      "Epoch 3/20\n",
      "8482/8482 [==============================] - 3s 366us/sample - loss: 0.1396 - acc: 0.9466 - val_loss: 0.1062 - val_acc: 0.9588\n",
      "Epoch 4/20\n",
      "8482/8482 [==============================] - 3s 365us/sample - loss: 0.1062 - acc: 0.9610 - val_loss: 0.0856 - val_acc: 0.9667\n",
      "Epoch 5/20\n",
      "8482/8482 [==============================] - 3s 368us/sample - loss: 0.0841 - acc: 0.9677 - val_loss: 0.1081 - val_acc: 0.9557\n",
      "Epoch 6/20\n",
      "8482/8482 [==============================] - 3s 367us/sample - loss: 0.0662 - acc: 0.9759 - val_loss: 0.0721 - val_acc: 0.9725\n",
      "Epoch 7/20\n",
      "8482/8482 [==============================] - 3s 371us/sample - loss: 0.0539 - acc: 0.9791 - val_loss: 0.0866 - val_acc: 0.9679\n",
      "Epoch 8/20\n",
      "8482/8482 [==============================] - 3s 380us/sample - loss: 0.0404 - acc: 0.9859 - val_loss: 0.1103 - val_acc: 0.9653\n",
      "Epoch 9/20\n",
      "8482/8482 [==============================] - 3s 387us/sample - loss: 0.0310 - acc: 0.9883 - val_loss: 0.0732 - val_acc: 0.9739\n",
      "Epoch 10/20\n",
      "8482/8482 [==============================] - 3s 377us/sample - loss: 0.0292 - acc: 0.9895 - val_loss: 0.0790 - val_acc: 0.9742\n",
      "Epoch 11/20\n",
      "8482/8482 [==============================] - 3s 379us/sample - loss: 0.0262 - acc: 0.9902 - val_loss: 0.0795 - val_acc: 0.9739\n",
      "Epoch 12/20\n",
      "8482/8482 [==============================] - 3s 385us/sample - loss: 0.0259 - acc: 0.9907 - val_loss: 0.0727 - val_acc: 0.9773\n",
      "Epoch 13/20\n",
      "8482/8482 [==============================] - 3s 397us/sample - loss: 0.0244 - acc: 0.9919 - val_loss: 0.0609 - val_acc: 0.9761\n",
      "Epoch 14/20\n",
      "8482/8482 [==============================] - 3s 395us/sample - loss: 0.0145 - acc: 0.9948 - val_loss: 0.0599 - val_acc: 0.9794\n",
      "Epoch 15/20\n",
      "8482/8482 [==============================] - 3s 411us/sample - loss: 0.0153 - acc: 0.9946 - val_loss: 0.0597 - val_acc: 0.9792\n",
      "Epoch 16/20\n",
      "8482/8482 [==============================] - 4s 416us/sample - loss: 0.0131 - acc: 0.9961 - val_loss: 0.0676 - val_acc: 0.9787\n",
      "Epoch 17/20\n",
      "8482/8482 [==============================] - 4s 425us/sample - loss: 0.0163 - acc: 0.9934 - val_loss: 0.0726 - val_acc: 0.9823\n",
      "Epoch 18/20\n",
      "8482/8482 [==============================] - 4s 430us/sample - loss: 0.0114 - acc: 0.9973 - val_loss: 0.0761 - val_acc: 0.9761\n",
      "Epoch 19/20\n",
      "8482/8482 [==============================] - 4s 419us/sample - loss: 0.0137 - acc: 0.9953 - val_loss: 0.0794 - val_acc: 0.9777\n",
      "Epoch 20/20\n",
      "8482/8482 [==============================] - 4s 442us/sample - loss: 0.0123 - acc: 0.9962 - val_loss: 0.0645 - val_acc: 0.9797\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten, Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "\n",
    "dense_layers = [1]\n",
    "layer_sizes = [64]\n",
    "conv_layers = [3]\n",
    "\n",
    "for dense_layer in dense_layers:\n",
    "    for layer_size in layer_sizes:\n",
    "        for conv_layer in conv_layers:\n",
    "\n",
    "#             NAME = f\"{conv_layer}-conv-{layer_size}-nodes-{dense_layer}-dense-{int(time.time())}\"\n",
    "#             tensorboard = TensorBoard(log_dir=f\"logs\\{NAME}\")\n",
    "\n",
    "            model = Sequential()\n",
    "\n",
    "            model.add(Conv2D(layer_size, (3, 3), input_shape=X_train.shape[1:], activation='relu'))\n",
    "            model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "            for l in range(conv_layer-1):\n",
    "                model.add(Conv2D(layer_size, (3, 3), activation='relu'))\n",
    "                model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "            model.add(Flatten())\n",
    "            for l in range(dense_layer):\n",
    "                model.add(Dense(layer_size, activation='relu'))\n",
    "                model.add(Dropout(0.2))\n",
    "\n",
    "            model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "            model.compile(loss=\"categorical_crossentropy\",\n",
    "                         optimizer=\"adam\",\n",
    "                         metrics=[\"accuracy\"])\n",
    "\n",
    "            model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=20) # , callbacks=[tensorboard])\n",
    "            \n",
    "# model.save('6ax3-CNN.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = tf.keras.models.load_model(\"6ax3-CNN.model\")\n",
    "\n",
    "test = \n",
    "prediction = model.predict('')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
